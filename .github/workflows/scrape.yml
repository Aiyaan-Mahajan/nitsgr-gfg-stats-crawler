# name: Scrape GFG Students

# on:
#   workflow_dispatch:
#   schedule:
#     - cron: '0 6 * * *' # runs daily at 6 AM UTC

# jobs:
#   scrape:
#     runs-on: ubuntu-latest

#     steps:
#       - name: Checkout repository
#         uses: actions/checkout@v3

#       - name: Set up Python
#         uses: actions/setup-python@v4
#         with:
#           python-version: '3.10'

#       - name: Install dependencies
#         run: |
#           python -m pip install --upgrade pip
#           pip install scrapy pandas

#       - name: Run spider
#         run: scrapy crawl gfgnitsgrstudents -o gfgnitsgrstudents.csv

#       - name: Commit output
#         run: |
#           git config user.name github-actions
#           git config user.email github-actions@github.com
#           git add gfgnitsgrstudents.csv
#           git commit -m "Update scraped data"
#           git push


name: Scrape GFG Students

on:
  workflow_dispatch:
  schedule:
    - cron: '0 6 * * *'  # Runs every day at 6 AM UTC

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install scrapy pandas

      - name: Run spider
        run: scrapy crawl gfgnitsgrstudents -o gfgnitsgrstudents.csv

      - name: Commit output
        env:
          TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          git config user.name github-actions
          git config user.email github-actions@github.com
          git add gfgnitsgrstudents.csv
          git commit -m "Update scraped data" || echo "No changes to commit"
          git push https://x-access-token:${TOKEN}@github.com/${{ github.repository }}.git HEAD:${{ github.ref_name }}
